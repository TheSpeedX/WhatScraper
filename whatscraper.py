import time
import sys
import re,os
import urllib.request,urllib.parse,threading
from colorama import Fore, init

init()

try:
	from googlesearch import search
except ImportError:
	print("No module named 'google' found")
	print("Please Install it By ")
	print("\tpython3 -m pip install google")
	exit()

SAVE="scrapped.txt"

def linkcheck(url):
	print(Fore.LIGHTCYAN_EX+'\n[#] Trying URL: '+Fore.LIGHTGREEN_EX+url,end='\r')
	try:
		r = urllib.request.urlopen(url)
	except KeyboardInterrupt:
			print(Fore.LIGHTRED_EX+'[!] Closing...')
			exit()
	except:
		return ("","")
	if(r.getcode()!=404):
		r=r.read().decode('utf-8')
		p=r.find('</h2>')
		name=r[r.rfind('">',0,p)+2:p]
		if name.strip()=="":
			return ("","")
		return (name,url)
	return ("","")
def pad(s):
	if not "invite" in s:
		p=s.find('.com')
		s=s[:p+4]+"/invite"+s[p+4:]
	return s
def scrape(txt):
	if type(txt)==type(b''):
		txt=txt.decode('utf-8')
	match=[]
	match1=re.findall(r'(https:\/\/chat\.whatsapp\.com\/[a-zA-Z0-9]{22})',txt)
	match2=re.findall(r'(https:\/\/chat\.whatsapp\.com\/invite\/[a-zA-Z0-9]{22})',txt)
	match+= match1 if not match1==None else []
	match+= match2 if not match2==None else []
	match=list(set(match))
	for lmt in match:
		lmt=pad(lmt)
		nm,url=linkcheck(lmt)
		if nm!='':
			print(Fore.LIGHTYELLOW_EX+'[$] Group Name: '+Fore.BLUE+(nm+" "*(65-len(nm))))
			print(Fore.LIGHTYELLOW_EX+'[$] Group Link: '+Fore.BLUE,url)
			f=open(SAVE,'ab')
			f.write(str.encode(nm+' : '+url+"\n"))
			f.close()
			
			f2=open('urls.txt', 'ab')
			f2.write(str.encode(url+"\n"))
			f2.close()
print(f"""

{Fore.LIGHTGREEN_EX} __      __.__            __   _________                                        
/  \    /  \  |__ _____ _/  |_/   _____/ ________________  ______   ___________ 
\   \/\/   /  |  \\\\__  \\\\   __\_____  \_/ ___\_  __ \__  \ \____ \_/ __ \_  __ \\
{Fore.LIGHTWHITE_EX} \        /|   Y  \/ __ \|  | /        \  \___|  | \// __ \|  |_> >  ___/|  | \/
  \__/\  / |___|  (____  /__|/_______  /\___  >__|  (____  /   __/ \___  >__|   
       \/       \/     \/            \/     \/           \/|__|        \/       
Compiled by HanzHaxors (https://github.com/HanzHaxors)
Coded by TheSpeedX (https://github.com/TheSpeedX)
{Fore.RESET}""")

if len(sys.argv)>=2:
	if "u" in sys.argv[1]:
		print("Updating Please Wait...")
		try:
			txt=urllib.request.urlopen(url).read()
			f=open(sys.argv[0],'wb')
			f.write(txt)
			f.close()
			print("\tUpdate Successful")
			print("Run "+sys.argv[0]+" Again..")
		except:
			print("Update Failed !!!")
		exit()
availabledom=['pastebin','throwbin','pastr','pasteio','paste2','paste']
def start(index):
	print("Initializing...")
	if index>=len(availabledom):
		return
	query = "intext:chat.whatsapp.com inurl:"+availabledom[index]
	print("Querying Google By Dorks ...")
	for url in search(query, tld="com", num=10, stop=None, pause=2):
		txt=urllib.request.urlopen(url).read().decode('utf8')
		scrape(txt)
threads= []
print("""
		1> Scrape Online
		2> Check From File
""")
try:
	inp=int(input("Enter Choice: "))
except:
	print("\t[!] Invalid Choice..")
	exit()
if inp==1:	
	f=open(SAVE,'w')
	f.write("Group Links Generated By WhatScrapper \nGet it at https://github.com/TheSpeedX/WhatScrapper\r\n")
	f.close()
	for i in range(0,int(input('Enter the number of threads(1-'+str(len(availabledom))+'):- '))):
		thread = threading.Thread(target=start,args=(i,))
		thread.start()
		threads.append(thread)

	for i in threads:
		i.join()
elif inp==2:
	path=input("Enter Whatsapp Link Path: ").strip()
	if not os.path.isfile(path):
		print('\tNo such file found...')
		exit()
	thn=int(input('Enter the number of threads: '))
	op=open(path,"rb").read().decode('utf-8')
	op=op.count('\n')//thn
	f=open(SAVE,'w')
	f.write("Group Links Generated By WhatScrapper \nGet it at https://github.com/TheSpeedX/WhatScrapper\r\n\r\n")
	f.close()
	with open(path,"rb") as strm:
		for i in range(thn-1):
			head = [next(strm) for x in range(op)]
			thread = threading.Thread(target=scrape,args=(b"\n".join(head),))
			thread.start()
			threads.append(thread)
		thread = threading.Thread(target=scrape,args=(strm.read(),))
		thread.start()
		threads.append(thread)
	for i in threads:
		i.join()
